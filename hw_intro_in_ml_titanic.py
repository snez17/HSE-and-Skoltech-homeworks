# -*- coding: utf-8 -*-
"""HW_Intro in ML_Titanic

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LDqdZqcy2KnDiF5oKP7IVekWKXBkX2tA
"""

!pip install opendatasets
!pip install pandas

import opendatasets as od
import pandas as pd

od.download(
    "https://www.kaggle.com/competitions/titanic/data")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from torch import tensor

from wordcloud import WordCloud
from sklearn import metrics
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import warnings
warnings.filterwarnings('ignore')

# reading the csv file
file =('titanic/\
train.csv')
train = pd.read_csv(file)

# displaying the contents of the csv file
train.head(2)

X_train = train.drop('Survived',axis=1)
y_train= train['Survived']

modes = X_train.mode().iloc[0]
modes

X_train.fillna(modes, inplace=True)

X_train['Fare'].hist()

X_train['LogFare'] = np.log(X_train['Fare']+1)

X_train['LogFare'].hist()

X_train = pd.get_dummies(X_train, columns=["Sex","Pclass","Embarked"])
X_train.columns

added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']
X_train[added_cols].head()

indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols

t_indep = tensor(X_train[indep_cols].values, dtype=float)
t_indep

X_train = X_train[indep_cols]
X_train.head(1)

X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,random_state=104,train_size=0.8, shuffle=True)

X_train.head(1)

X_test.head(1)

# т.е. приведем данные к нулевому среднему и единичному СКО
X_train = (X_train - X_train.mean()) / X_train.std()
X_train.head(2)

"""обработаем валидационный датасет (к которому нет предсказаний)"""

# reading the csv file
file =('titanic/\
test.csv')
X_val = pd.read_csv(file)

# displaying the contents of the csv file
X_val.head(2)

modes_test = X_val.mode().iloc[0]
modes_test

X_val.fillna(modes_test, inplace=True)

X_val = pd.get_dummies(X_val, columns=["Sex","Pclass","Embarked"])
X_val.columns

added_cols_test = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']
X_val[added_cols_test].head(1)

X_val['LogFare'] = np.log(X_val['Fare']+1)

indep_cols_test = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols_test

t_indep_test = tensor(X_val[indep_cols_test].values, dtype=float)
t_indep_test

X_val = X_val[indep_cols_test]
##важно

"""Задачи:

А. Решение задачи классификации

**1. Построить модель линейной классификации. При решении задачи методом
градиентного спуска, необходимо вычислить градиент с помощью матрицы
признаков.**
"""

from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import RandomForestClassifier

# Stochastic Gradient Descent
sgd = SGDClassifier()
sgd.fit(X_train, y_train)
Y_pred = sgd.predict(X_test)
acc_sgd = round(sgd.score(X_train, y_train) * 100, 2)
acc_sgd

"""Градиентный спуск - это приятный и простой метод минимизации среднеквадратичной ошибки в задаче классификации или регрессии."""

def add_ones(x):
  # важно! метод .insert() изменяет исходный датафрейм
  return x.insert(0,'x0', np.ones(x.shape[0]))

# добавим столбец с единицами
add_ones(X_train)

# и посмотрим на результат
X_train.head(2)

thetas, n = np.zeros(X_train.shape[1]), X_train.shape[0]
thetas, n

def stable_sigmoid(z):
  if z >= 0:
      return 1 / (1 + np.exp(-z))
  else:
      return np.exp(z) / (np.exp(z) + 1)

loss_history = []

def h(x, thetas):
  z = np.dot(x, thetas)
  return 1.0 / (1 + np.exp(-z))

# возьмем большое положительное значение
z = 999
1 / (1 + np.exp(-z))

# возьмем большое отрицательное значение
z = -999
1 / (1 + np.exp(-z))

def h(x, thetas):
  z = np.dot(x, thetas)

  return np.array([stable_sigmoid(value) for value in z])

A = np.linalg.pinv(X_train)
W = np.dot(A,y_train)
W

# возьмем массив наблюдений
x = X_train

# и вектор коэффициентов
thetas = W

# подадим их в модель
h(x, thetas)

def objective(y, y_pred):

  # рассчитаем функцию потерь для y = 1, добавив 1e-9, чтобы избежать ошибки при log(0)
  y_one_loss = y * np.log(y_pred + 1e-9)

  # также рассчитаем функцию потерь для y = 0
  y_zero_loss = (1 - y) * np.log(1 - y_pred + 1e-9)

  # сложим и разделим на количество наблюдений
  return -np.mean(y_zero_loss + y_one_loss)

def gradient(x, y, y_pred, n):
  return np.dot(x.T, (y_pred - y)) / n

# в цикле из 200 итераций
for i in range(200):
  # рассчитаем прогнозное значение с текущими весами
  y_pred = h(X_train, thetas)
  # посчитаем уровень ошибки при текущем прогнозе
  loss_history.append(objective(y_train, y_pred))
  # рассчитаем градиент
  grad = gradient(X_train, y_train, y_pred, n)
  # используем градиент для улучшения весов модели
  # коэффициент скорости обучения будет равен 0,001
  thetas = thetas - 0.001 * grad

# чтобы посмотреть финальный уровень ошибки,
# достаточно взять последний элемент списка loss_history
thetas, loss_history[-1]

"""**2. Построить модель на основе случайного леса классифицирующих деревьев.
Определить параметры классификатора (количество деревьев, максимальная
глубина дерева), при которых точность классификации максимальна.**
"""

# Random Forest

random_forest = RandomForestClassifier(n_estimators=39,max_depth=19, random_state=1)
random_forest.fit(X_train, y_train)
Y_pred = random_forest.predict(X_test)
random_forest.score(X_train, y_train)
acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)
acc_random_forest

Y_pred_2 = random_forest.predict(X_test)

"""Б. Анализ ROC/PR-кривых

**1. Рассмотреть простейшую задачу двухклассовой классификации, в которой
элементы выборки имеют нормальное распределение с дисперсией 1 и
средними значениями +μ для экземпляров одного класса и -μ для экземпляров
другого класса. Экземпляры каждого класса появляются в обучающей выборке
с вероятностью 1⁄2. Для данной задачи необходимо определить оптимальный
классификатор, а также построить ROC-кривую для различных значений μ.**
"""

x = np.array([[-1,1,-1,1,-1,1,-1,1,-1,1],[0,1,0,1,0,1,0,1,0,1]])
x= x.T
x = pd.DataFrame(columns=['indep', 'dep'],data=x)
X_t=x['indep']
Y_tr=x['dep']

X_t=pd.DataFrame(X_t)
Y_tr=pd.DataFrame(Y_tr)

X_tr, X_t, y_tr, y_t = train_test_split(X_t,Y_tr,train_size=0.8, shuffle=True)

logreg = LogisticRegression()
logreg.fit(X_tr, y_tr)
Y_pred = logreg.predict(X_t)
Y_pred

lr_auc = roc_auc_score(y_t, Y_pred)
lr_auc

# рассчитываем roc-кривую
fpr, tpr, treshold = roc_curve(y_t, Y_pred)
roc_auc = auc(fpr, tpr)
# строим график
plt.plot(fpr, tpr, color='darkorange',
         label='ROC кривая (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

"""**2. Для двух моделей, полученных в п.А., построить ROC и PR (precision-recall) кривые. Получить значения площадей под этими кривыми. Какая метрика (ROC-AUC или PR-AUC) является более предпочтительной в данном примере и почему?**"""

sgd_output = pd.DataFrame({'Survived': Y_pred})
sgd_output.head(2)

auc_score = roc_auc_score(y_test, Y_pred)
auc_score

from sklearn.metrics import average_precision_score, precision_recall_curve

# Average precision score
average_precision = average_precision_score(y_test, Y_pred)
print(average_precision)

rfc_output = pd.DataFrame({'Survived': Y_pred_2})
rfc_output.head(2)

auc_score_2 = roc_auc_score(y_test, Y_pred_2)
auc_score_2

# Average precision score
average_precision_2 = average_precision_score(y_test, Y_pred_2)
print(average_precision_2)

"""AUC-ROC измеряет долю False Positive относительно True Negative и в задачах, где нам не так важен второй (больший) класс, может давать не совсем адекватную картину при сравнении алгоритмов.

 Precision и recall не зависят от соотношения классов и применимы в условиях несбалансированных выборок. True Positive измеряется относительно True Negative.

 В связи с этим, в данной задаче лучшей метрикой для даной задачи является Precision-Recall.

При выполнении задания использовались:

https://habr.com/ru/companies/ods/articles/328372/

https://loginom.ru/blog/classification-quality?ysclid=lqjo7dhi91854287473

https://www.kaggle.com/code/alexisbcook/titanic-tutorial
"""